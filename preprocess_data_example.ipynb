{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, preprocess and align offshore swell observations with surf height observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read surf height observations\n",
    "Import surf height observations and convert ymd to a date index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.head of             year  month  day  nshor  wshor  almo  dh  winw  wspd  wdir  nsd  \\\n",
      "date                                                                          \n",
      "2010-01-01  2010      1    1      6      4     2   3     4     3     2   16   \n",
      "2010-01-02  2010      1    2      7      4     2   2     3     2    17   14   \n",
      "2010-01-03  2010      1    3      6      4     2   2     2     4    11   15   \n",
      "2010-01-04  2010      1    4      6      3     2   2     2     4    11   14   \n",
      "2010-01-05  2010      1    5     18      6     2   2     2     4    11   14   \n",
      "2010-01-06  2010      1    6     15      4     2   2     2     3    13   14   \n",
      "2010-01-07  2010      1    7     15      8     3   4     2     3     2   14   \n",
      "2010-01-08  2010      1    8     15      6     3   3     2     2    17   15   \n",
      "2010-01-09  2010      1    9     10      5     2   2     4     4    11   16   \n",
      "2010-01-10  2010      1   10      7      4     2   2     2     4    13   15   \n",
      "2010-01-11  2010      1   11     27     15     2   2     6     3     2   15   \n",
      "2010-01-12  2010      1   12     15      8     2   2     4     3     5   15   \n",
      "2010-01-13  2010      1   13     12      6     3   3     4     6    13   14   \n",
      "2010-01-14  2010      1   14     15     12     2   2     4     5     1   15   \n",
      "2010-01-15  2010      1   15      8      5     1   2     4     3     4   16   \n",
      "2010-01-16  2010      1   16     12      8     1   2     3     3     5   15   \n",
      "2010-01-17  2010      1   17     18     15     1   2     3     3     5   15   \n",
      "2010-01-18  2010      1   18     15     10     1   2     3     3     3   15   \n",
      "2010-01-19  2010      1   19     10      8     1   2     3     4     3   16   \n",
      "2010-01-20  2010      1   20      7      3     2   3     4     6     4   16   \n",
      "2010-01-21  2010      1   21      6      3     2   3     4     4     5   16   \n",
      "2010-01-22  2010      1   22      7      2     1   2     3     3     7   16   \n",
      "2010-01-23  2010      1   23      5      2     1   2     3     3     9    1   \n",
      "2010-01-24  2010      1   24     10      6     2   3     3     3     9   16   \n",
      "2010-01-25  2010      1   25      5      2     2   3     3     2    17    1   \n",
      "2010-01-26  2010      1   26      4      2     3   3     3     4     9   15   \n",
      "2010-01-27  2010      1   27     18      8     3   3     3     4     1   14   \n",
      "2010-01-28  2010      1   28     15      8     3   3     4     4     4   15   \n",
      "2010-01-29  2010      1   29      8      5     3   3     4     2    17   16   \n",
      "2010-01-30  2010      1   30      4      2     2   2     2     3     1   16   \n",
      "...          ...    ...  ...    ...    ...   ...  ..   ...   ...   ...  ...   \n",
      "2016-12-02  2016     12    2     12      6     2   3     6     5     5   14   \n",
      "2016-12-03  2016     12    3      9      4     2   3     4     2    17   15   \n",
      "2016-12-04  2016     12    4      8      3     2   3     4     2    17   16   \n",
      "2016-12-05  2016     12    5      5      2     2   3     4     2    17   16   \n",
      "2016-12-06  2016     12    6      4      2     2   3     3     2    17    1   \n",
      "2016-12-07  2016     12    7      6      3     2   3     3     2    17   14   \n",
      "2016-12-08  2016     12    8      4      2     1   2     2     2    17   14   \n",
      "2016-12-09  2016     12    9      3      1     1   1     2     2    17    1   \n",
      "2016-12-10  2016     12   10      4      1     1   1     3     2    17    1   \n",
      "2016-12-11  2016     12   11      4      1     1   1     3     2    17    2   \n",
      "2016-12-12  2016     12   12      5      3     1   1     3     3     1   15   \n",
      "2016-12-13  2016     12   13      3      2     1   1     2     4     2   15   \n",
      "2016-12-14  2016     12   14      7      2     1   1     7     4     4    2   \n",
      "2016-12-15  2016     12   15      4      1     1   1     5     4    15    2   \n",
      "2016-12-16  2016     12   16     15      8     2   2     6     4    13   16   \n",
      "2016-12-17  2016     12   17      9      5     2   2     5     4    11   16   \n",
      "2016-12-18  2016     12   18      6      4     2   2     5     4     9   16   \n",
      "2016-12-19  2016     12   19      5      2     1   2     3     3     5   15   \n",
      "2016-12-20  2016     12   20      6      3     1   2     3     4     4   16   \n",
      "2016-12-21  2016     12   21      8      5     1   2     3     4     4   16   \n",
      "2016-12-22  2016     12   22      7      4     1   2     3     4     5   15   \n",
      "2016-12-23  2016     12   23      5      2     2   2     3     3     5   15   \n",
      "2016-12-24  2016     12   24      3      2     2   2     3     5     4   15   \n",
      "2016-12-25  2016     12   25     15     10     2   2     4     5     4   15   \n",
      "2016-12-26  2016     12   26      8      5     2   2     5     6     5   16   \n",
      "2016-12-27  2016     12   27      4      2     1   2     4     6     5   15   \n",
      "2016-12-28  2016     12   28      3      1     1   2     3     5     3   15   \n",
      "2016-12-29  2016     12   29     10      2     1   1     6     4     3   16   \n",
      "2016-12-30  2016     12   30      6      2     1   1     5     5     2    2   \n",
      "2016-12-31  2016     12   31      4      1     1   1     4     4     3    2   \n",
      "\n",
      "            ssd  \n",
      "date             \n",
      "2010-01-01   13  \n",
      "2010-01-02  999  \n",
      "2010-01-03  999  \n",
      "2010-01-04  999  \n",
      "2010-01-05  999  \n",
      "2010-01-06  999  \n",
      "2010-01-07  999  \n",
      "2010-01-08  999  \n",
      "2010-01-09  999  \n",
      "2010-01-10  999  \n",
      "2010-01-11  999  \n",
      "2010-01-12  999  \n",
      "2010-01-13  999  \n",
      "2010-01-14  999  \n",
      "2010-01-15  999  \n",
      "2010-01-16  999  \n",
      "2010-01-17  999  \n",
      "2010-01-18  999  \n",
      "2010-01-19  999  \n",
      "2010-01-20  999  \n",
      "2010-01-21  999  \n",
      "2010-01-22  999  \n",
      "2010-01-23  999  \n",
      "2010-01-24  999  \n",
      "2010-01-25    8  \n",
      "2010-01-26    9  \n",
      "2010-01-27   13  \n",
      "2010-01-28   13  \n",
      "2010-01-29   13  \n",
      "2010-01-30  999  \n",
      "...         ...  \n",
      "2016-12-02   10  \n",
      "2016-12-03   10  \n",
      "2016-12-04   10  \n",
      "2016-12-05   10  \n",
      "2016-12-06   10  \n",
      "2016-12-07    9  \n",
      "2016-12-08  999  \n",
      "2016-12-09  999  \n",
      "2016-12-10  999  \n",
      "2016-12-11  999  \n",
      "2016-12-12  999  \n",
      "2016-12-13  999  \n",
      "2016-12-14  999  \n",
      "2016-12-15  999  \n",
      "2016-12-16  999  \n",
      "2016-12-17  999  \n",
      "2016-12-18  999  \n",
      "2016-12-19  999  \n",
      "2016-12-20  999  \n",
      "2016-12-21  999  \n",
      "2016-12-22  999  \n",
      "2016-12-23   11  \n",
      "2016-12-24   11  \n",
      "2016-12-25   10  \n",
      "2016-12-26   10  \n",
      "2016-12-27  999  \n",
      "2016-12-28  999  \n",
      "2016-12-29  999  \n",
      "2016-12-30  999  \n",
      "2016-12-31  999  \n",
      "\n",
      "[2557 rows x 12 columns]>\n",
      "(2557, 12)\n"
     ]
    }
   ],
   "source": [
    "obs_dat = pd.read_table(\"./data/oahu_all.dat\", delim_whitespace=True, names=[\"year\", \"month\", \"day\", \"nshor\", \"wshor\", \"almo\", \"dh\", \"winw\", \"wspd\", \"wdir\", \"nsd\", \"ssd\"])\n",
    "obs_dat['date'] = pd.to_datetime(obs_dat.year*10000+obs_dat.month*100+obs_dat.day,format='%Y%m%d')\n",
    "obs_dat = obs_dat.set_index(\"date\")\n",
    "print obs_dat.head\n",
    "print obs_dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import buoy data / offshore observation\n",
    "Import data from the offshore sensor.\n",
    "\n",
    "- Shift GMT into Hawaiian local time\n",
    "- Remove data before and after sunset (When we presume observation would be impossible)\n",
    "- Filter data to give only rows with maximum daily WVHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all years and concatenate\n",
    "all_dat = []\n",
    "for year in range(2010, 2017):\n",
    "    dat = pd.read_table(\"./data/buoy_\"+str(year)+\".dat\", delim_whitespace=True, skiprows=3, names=[\"YYYY\", \"MM\", \"DD\", \"hh\", \"mm\", \"WDIR\", \"WSPD\", \"GST\",  \"WVHT\", \"DPD\", \"APD\", \"MWD\", \"PRES\", \"ATMP\", \"WTMP\", \"DEWP\",  \"VIS\", \"TIDE\"])\n",
    "    all_dat.append(dat)\n",
    "dat = pd.concat(all_dat)\n",
    "\n",
    "# Convert the date columns into a datetime index\n",
    "dat['date'] = pd.to_datetime(dat.YYYY.astype(str)+\"-\"+dat.MM.astype(str)+\"-\"+dat.DD.astype(str)+\" \"+dat.hh.astype(str)+\":\"+dat.mm.astype(str)+\":00\")\n",
    "dat = dat.set_index(pd.DatetimeIndex(dat['date']))\n",
    "\n",
    "# The buoy data is reported in GMT but the observations are in Hawaiian time. Given the observations are 'maximum'\n",
    "# value in day we don't have to be too precise here (eg. worry about DST) but we do need to shift this data.\n",
    "dat.index = dat.index + timedelta(hours=-10)\n",
    "\n",
    "# We know (or assume!) observations are taken during daylight hours. Again with the imprecision inherent in the \n",
    "# observation data we probably don't gain by over thinking this but here's a filter:\n",
    "hour = dat.index.hour\n",
    "selector = ((hour >= 7) & (hour <= 17))\n",
    "dat= dat[selector]\n",
    "\n",
    "# We know the observations are for the daily largest heights. Here we'll filter our buoy data to just the daily\n",
    "# row with the largest WVHT value. This presumes WVHT is a correlate with our observed heights and that assumption\n",
    "# will predjudice our model outcomes. Feel free to use a different method!\n",
    "idx = dat.groupby(\n",
    "            ([dat.index.year, dat.index.month, dat.index.day])\n",
    "            )['WVHT'].transform(max) == dat['WVHT']\n",
    "\n",
    "dat = dat[idx]\n",
    "\n",
    "idx = dat.resample('d').max()\n",
    "\n",
    "buoy_dat = idx\n",
    "\n",
    "buoy_dat = buoy_dat.replace(99.0, np.nan)\n",
    "\n",
    "print buoy_dat.head\n",
    "print buoy_dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge our date sets on date\n",
    "Merge such that each row now represents the human observed surf heights for that day with the largest sensor observed offshore wave heights and all corresponding sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dat = pd.merge(buoy_dat,obs_dat, how='outer', left_index=True, right_index=True)\n",
    "print all_dat.shape\n",
    "print all_dat.iloc[200:400]['WVHT']\n",
    "print all_dat.iloc[200:400]['nshor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize / Check the data\n",
    "Plotting timeseries from both WVHT and nshore shows some correlation - enough to suggest we're on the right track\n",
    "but with more than enough variance to suggest that a successful model might want to investigate other features eg DPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "test_WVHT = all_dat['WVHT'][500:1000] * 3.28 # NB Converted Meters to Feet\n",
    "test_nshor = all_dat['nshor'][500:1000]\n",
    "plt.plot(test_WVHT) # Convert meters to feet\n",
    "plt.plot(test_nshor) # Observations are half actual face height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(test_WVHT, test_nshor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_dat.to_csv(\"./data/preprocessed_all.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
